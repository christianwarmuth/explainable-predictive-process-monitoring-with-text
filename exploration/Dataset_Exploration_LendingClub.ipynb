{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration - Lending Club"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Prerequesites - Installing of packages and Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "import pandas as pd\n",
    "import toml\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "from nltk import word_tokenize \n",
    "from nltk.util import ngrams\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re, nltk, spacy, gensim\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.utils import *\n",
    "\n",
    "import pylab as pl\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = toml.load(\"config.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc = pd.read_csv(config[\"data\"][\"lending_club_acc\"])\n",
    "df_rej = pd.read_csv(config[\"data\"][\"lending_club_rej\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. First Investigations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rej.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rej[\"Loan Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc[\"id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.min_rows\", 20):\n",
    "    print(df_rej[\"Loan Title\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc[\"loan_status\"].unique()\n",
    "with pd.option_context(\"display.min_rows\", 50):\n",
    "    print(df_acc[\"loan_status\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization & Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_acc.shape)\n",
    "df_acc = df_acc[df_acc['desc'].notnull() & df_acc['title'].notnull()]\n",
    "print(df_acc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (7,6)\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "df_acc['desc_word_count'] = df_acc['desc'].str.count(' ') + 1\n",
    "\n",
    "df_acc['desc_word_count'].hist(bins=60, grid=False, figsize=(12,8), color='#2077B4', zorder=2, rwidth=0.9)\n",
    "pl.title(\"Histogram of Text Lengths for Loan Goal Descriptions\", fontsize=22)\n",
    "pl.xlabel(\"Text Length\", fontsize=18)\n",
    "pl.ylabel(\"Cumulative count\", fontsize=18)\n",
    "pl.xticks(fontsize=14)\n",
    "pl.yticks(fontsize=14)\n",
    "pl.axvline(x=45.5, ymin=0, ymax=1, linewidth=3, color=\"#000000\")\n",
    "pl.savefig('charts/hist_text_lengths.png', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc['desc_word_count'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc = df_acc[['desc', 'title', 'desc_word_count']]\n",
    "df_acc = df_acc[df_acc['desc_word_count'] > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longest Loan Goal Title\n",
    "df_acc.loc[df_acc['desc_word_count'].idxmax()]['desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc[\"desc\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_cols = [\"title\", \"desc\"]\n",
    "for col in nlp_cols:\n",
    "    replace_empties = lambda x: x if re.search(\"\\S\", x) else np.NaN\n",
    "    df_acc[col] = df_acc[col].map(replace_empties, na_action=\"ignore\")\n",
    "\n",
    "description = df_acc[nlp_cols].describe()\n",
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_loans = df_acc.shape[0]\n",
    "\n",
    "for col in nlp_cols:\n",
    "    percentage = int(description.at[\"count\", col] / num_loans * 100)\n",
    "    print(f\"`{col}` is used in {percentage}% of loans in the dataset.\")\n",
    "\n",
    "percentage = int(description.at[\"freq\", \"title\"] / num_loans * 100)\n",
    "print(f'The title \"Debt consolidation\" is used in {percentage}% of loans.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete HTML Tags and 'Borrower Added' Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"^\\s*Borrower added on \\d\\d/\\d\\d/\\d\\d > \"\n",
    "\n",
    "other_desc_map = df_acc[\"desc\"].map(\n",
    "    lambda x: True if pd.isna(x) or re.search(pattern, x, re.I) else False\n",
    ")\n",
    "other_descs = df_acc[\"desc\"][other_desc_map]\n",
    "other_descs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleans all <Borrower added...> and <br> tags\n",
    "def clean_desc(desc):\n",
    "    if pd.isna(desc):\n",
    "        return desc\n",
    "    else:\n",
    "        desc = re.sub(\n",
    "            \"^\\s*Borrower added on \\d\\d/\\d\\d/\\d\\d > |<br>\", lambda x: \" \", desc\n",
    "        ).strip()\n",
    "        return re.sub(\n",
    "            \"<br>\", lambda x: \" \", desc\n",
    "        ).strip()\n",
    "df_acc[\"desc\"] = df_acc[\"desc\"].map(clean_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc[\"desc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Topic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Text Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc = df_acc.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_desc = []\n",
    "corpus_title = []\n",
    "\n",
    "for element in df_acc[\"desc\"].tolist():\n",
    "    corpus_desc.append(element.split())\n",
    "\n",
    "for element in df_acc[\"title\"].tolist():\n",
    "    corpus_title.append(element.split())\n",
    "\n",
    "corpus_flat = [item for sublist in corpus_desc for item in sublist]\n",
    "for i in range(len(corpus_flat)):\n",
    "    corpus_flat[i] = corpus_flat[i].lower()\n",
    "    \n",
    "counts = Counter(corpus_flat)\n",
    "#print(counts)\n",
    "df_word_counts = pd.DataFrame.from_dict(counts.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (7,6)\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "\n",
    "y_pos = np.arange(25)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.bar(y_pos, df_word_counts[1][:25], align='center', color='#2077B4')\n",
    "plt.xticks(y_pos, df_word_counts[0][:25].values,rotation='vertical')\n",
    "plt.ylabel('Frequency', fontsize=18)\n",
    "plt.xlabel('Tokens', fontsize=18)\n",
    "pl.xticks(fontsize=14)\n",
    "pl.yticks(fontsize=14)\n",
    "plt.title('Top 25 tokens by occurance in LendingClub dataset', fontsize=22)\n",
    "plt.savefig('charts/top_25_tokens.png', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (7,6)\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "\n",
    "y_pos = np.arange(500)\n",
    "plt.figure(figsize=(12,8))\n",
    "s = 1\n",
    "expected_zipf = [df_word_counts[1][0]/(i+1)**s for i in y_pos]\n",
    "plt.bar(y_pos, df_word_counts[1][:500], align='center',color = \"#2077B4\")\n",
    "#plt.plot(y_pos, expected_zipf, color='r', linestyle='--',linewidth=2,alpha=0.5)\n",
    "plt.ylabel('Frequency',fontsize=18)\n",
    "pl.xticks(fontsize=14)\n",
    "pl.yticks(fontsize=14)\n",
    "plt.title('Top 500 tokens in LendingClub dataset', fontsize=22)\n",
    "plt.savefig('charts/top_500_tokens.png', dpi=150)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c554f659d074aced482facc4fe92d47b1d41b5388ea4ac349637d7b67f90d4c7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
